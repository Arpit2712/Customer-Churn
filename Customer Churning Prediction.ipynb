{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_auc_score, roc_curve, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Churn Modeling.csv\")\n",
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "# There are 10,000 rows and 14 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# Checking the information of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# There are no null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Exited'].value_counts()\n",
    "# As it can be seen this dataset's targer column is imbalanced there are 7963 zero's and 2037 one's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# The describe function will display all the decriptive statistics of the data including mean, std, min, max values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()\n",
    "# The nunique() function is used to count distinct observations over requested axis. Return Series with number of distinct observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "# Displaying the column names of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df)\n",
    "# Displaying scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "# Displaying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)\n",
    "# Displaying the head of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Geography',y='EstimatedSalary',hue='Gender',color='teal',data=df);\n",
    "# Visualizing barplot where Geography is on x-axis and estimated salary is on y axis and key is gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Age',y='EstimatedSalary',data=df);\n",
    "# Visualizing barplot where age is taken on x axis and estimated salary is taken on y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Age',y='Exited',color='teal',data=df);\n",
    "# Visualizing barplot where age is taken on x axis and exited in on y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Gender',y='EstimatedSalary',color='orange',data=df);\n",
    "# Visualizing barplot where gender is taken on x axis and estimated salary is taken on y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Gender',y='Balance',color='teal',data=df);\n",
    "# Visualizing barplot where Gender is taken on x axis and Balance is taken on y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Age',y='EstimatedSalary',hue='Gender',data=df);\n",
    "# Visualizing barplot where Age is taken on x axis and EstimatedSalary is taken on y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Age',y='NumOfProducts',data=df);\n",
    "# Visualizing barplot where Age is taken on x axis and NumOfProducts is taken on y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='NumOfProducts',y='EstimatedSalary',data=df);\n",
    "# Visualizing barplot where NumOfProducts is taken on x axis and EstimatedSalary is taken on y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='Age',y='Tenure',hue='Gender',data=df);\n",
    "# Visualizing barplot where Age is taken on x axis and Tenure is taken on y axis and key is gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='IsActiveMember',y='Geography',hue='Gender',data=df);\n",
    "# Visualizing barplot where IsActiveMember is taken on x axis and Geography is taken on y axis and key is gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='IsActiveMember',y='Exited',hue='Gender',data=df);\n",
    "# Visualizing barplot where IsActiveMember is taken on x axis and Exited is taken on y axis and key is gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='IsActiveMember',y='EstimatedSalary',hue='Gender',data=df);\n",
    "# Visualizing barplot where IsActiveMember is taken on x axis and EstimatedSalary is taken on y axis and key is gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='HasCrCard',y='Exited',hue='Gender',data=df); \n",
    "# Visualizing barplot where HasCrCard is taken on x axis and Exited is taken on y axis and key is gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='HasCrCard',y='Geography',hue='Gender',data=df);\n",
    "# Visualizing barplot where HasCrCard is taken on x axis and Geography is taken on y axis and key is gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['Geography','Gender']\n",
    "le=LabelEncoder()\n",
    "for i in cat_cols:\n",
    "    df[i]=le.fit_transform(df[i])\n",
    "df.dtypes    \n",
    "# We convert categorical data into numeric data with the help of label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()\n",
    "# displaying columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber'],axis=1,inplace=True)\n",
    "df.drop(['CustomerId'],axis=1,inplace=True)\n",
    "df.drop(['Surname'],axis=1,inplace=True)\n",
    "# dropping uneccessary columns and removing them from the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistributionPlot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=2\n",
    "cols=5\n",
    "fig, ax=plt.subplots(nrows=rows,ncols=cols,figsize=(16,4))\n",
    "col=df.columns\n",
    "index=0\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        sns.distplot(df[col[index]],ax=ax[i][j])\n",
    "        index=index+1\n",
    "        \n",
    "plt.tight_layout()\n",
    "# Distribution plot will help us to check if the data is skewed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(labels=['Exited'],axis=1)\n",
    "Y=df['Exited']\n",
    "X.head()\n",
    "# Splitting data into dependent and independent columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()\n",
    "# This is the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=40)\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n",
    "# Splitting the data set into training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "log_reg = LogisticRegression().fit(X_train, Y_train)\n",
    "\n",
    "#predict on train \n",
    "train_preds = log_reg.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds))\n",
    "\n",
    "#predict on test\n",
    "test_preds = log_reg.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds).sum(),'/',((Y_test == test_preds).sum()+(Y_test != test_preds).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score.\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "NB=GaussianNB()\n",
    "NB.fit(X_train,Y_train)\n",
    "\n",
    "#predict on train \n",
    "train_preds2 = NB.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds2))\n",
    "\n",
    "#predict on test\n",
    "test_preds2 = NB.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds2))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds2))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds2))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds2))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds2))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds2).sum(),'/',((Y_test == test_preds2).sum()+(Y_test != test_preds2).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "DT = DecisionTreeClassifier().fit(X,Y)\n",
    "\n",
    "#predict on train \n",
    "train_preds3 = DT.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds3))\n",
    "\n",
    "#predict on test\n",
    "test_preds3 = DT.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds3))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds3))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds3))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds3))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds3))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds3).sum(),'/',((Y_test == test_preds3).sum()+(Y_test != test_preds3).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "RF=RandomForestClassifier().fit(X_train,Y_train)\n",
    "#predict on train \n",
    "train_preds4 = RF.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds4))\n",
    "\n",
    "#predict on test\n",
    "test_preds4 = RF.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds4))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds4))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds4))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds4))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds4))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds4).sum(),'/',((Y_test == test_preds4).sum()+(Y_test != test_preds4).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "KNN = KNeighborsClassifier().fit(X_train,Y_train)\n",
    "#predict on train \n",
    "train_preds5 = KNN.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds5))\n",
    "\n",
    "#predict on test\n",
    "test_preds5 = KNN.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds5))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds5))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds5))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds5))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds5))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds5).sum(),'/',((Y_test == test_preds5).sum()+(Y_test != test_preds5).sum()))\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "SVM = SVC(kernel='linear')\n",
    "SVM.fit(X_train, Y_train)\n",
    "\n",
    "#predict on train \n",
    "train_preds6 = SVM.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds6))\n",
    "\n",
    "#predict on test\n",
    "test_preds6 = SVM.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds6))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds6))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds6))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds6))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds6))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "print(\"recall\", metrics.recall_score(Y_test, test_preds6))\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds6).sum(),'/',((Y_test == test_preds6).sum()+(Y_test != test_preds6).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG-Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr =xgb.XGBClassifier().fit(X_train, Y_train)\n",
    "\n",
    "#predict on train \n",
    "train_preds7 = xgbr.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds7))\n",
    "\n",
    "#predict on test\n",
    "test_preds7 = xgbr.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds7))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds7))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds7))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds7))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds7))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "print(\"recall\", metrics.recall_score(Y_test, test_preds7))\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds7).sum(),'/',((Y_test == test_preds7).sum()+(Y_test != test_preds7).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier and Xg-boost Regressor model performed well compared to other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "RFT=RandomForestClassifier(n_estimators=500,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',random_state=235,verbose=2,max_samples=50).fit(X_train,Y_train)\n",
    "#predict on train \n",
    "train_preds8 = RFT.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds8))\n",
    "\n",
    "#predict on test\n",
    "test_preds8 = RFT.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds8))\n",
    "print('-'*50)\n",
    "\n",
    "#We got good accuracy which means our model is performing quite well \n",
    "#ROC \n",
    "print(\"ROC score on train is: \", roc_auc_score(Y_train, train_preds8))\n",
    "print(\"ROC score on test is: \", roc_auc_score(Y_test, test_preds8))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds8))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds8))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds8).sum(),'/',((Y_test == test_preds8).sum()+(Y_test != test_preds8).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. RandomSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 5000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 2000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFT1=RandomForestClassifier()\n",
    "rf_randomcv=RandomizedSearchCV(estimator=RFT1,param_distributions=random_grid,n_iter=100,cv=5,verbose=2,\n",
    "                               random_state=100,n_jobs=-1)\n",
    "### fit the randomized model\n",
    "rf_randomcv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv.best_params_\n",
    "# best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv\n",
    "# displaying all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv.best_estimator_\n",
    "# Displaying best parameters from all parameters mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_grid=rf_randomcv.best_estimator_\n",
    "# saving all parameters in best_random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=best_random_grid.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(Y_test,Y_pred)))\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=Y_pred).sum(),'/',((Y_test == Y_pred).sum()+(Y_test != Y_pred).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,Y_pred))\n",
    "# predicting the randomised search cv models parameters and evaluating the random forest model using evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. GridSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Using grid search cv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_randomcv.best_params_\n",
    "# Visualizing the best parameters of random cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': [rf_randomcv.best_params_['criterion']],\n",
    "    'max_depth': [rf_randomcv.best_params_['max_depth']],\n",
    "    'max_features': [rf_randomcv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [rf_randomcv.best_params_['min_samples_leaf'], \n",
    "                         rf_randomcv.best_params_['min_samples_leaf']+2, \n",
    "                         rf_randomcv.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [rf_randomcv.best_params_['min_samples_split'] - 2,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] - 1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'], \n",
    "                          rf_randomcv.best_params_['min_samples_split'] +1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [rf_randomcv.best_params_['n_estimators'] - 200, rf_randomcv.best_params_['n_estimators'] - 100, \n",
    "                     rf_randomcv.best_params_['n_estimators'], \n",
    "                     rf_randomcv.best_params_['n_estimators'] + 100, rf_randomcv.best_params_['n_estimators'] + 200]\n",
    "}\n",
    "\n",
    "print(param_grid)\n",
    "# creating a param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()\n",
    "grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=10,n_jobs=-1,verbose=2)\n",
    "grid_search.fit(X_train,Y_train)\n",
    "# Fitting the grid_search to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_\n",
    "# best parameters of grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid=grid_search.best_estimator_\n",
    "# saving the parameters in best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid\n",
    "# Displaying best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_grid.predict(X_test)\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(\"Accuracy Score {}\".format(accuracy_score(Y_test,y_pred)))\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=y_pred).sum(),'/',((Y_test == y_pred).sum()+(Y_test != y_pred).sum()))\n",
    "print('-'*50)\n",
    "\n",
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,y_pred))\n",
    "# Predicting the grid search cv on random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The decision tree model showed us overfitting problem.\n",
    "#### Hence the randomised search cv on random forest classifier gave us better accuracy which is 87 percent and wrong predictions made by the model are 243/2000 and grid search cv gave us 87 percent accuracy and wrong predictions are 246/2000. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
